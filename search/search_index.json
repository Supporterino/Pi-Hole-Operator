{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pi\u2011Hole Operator","text":"<p>Early\u2011Stage Project</p> <p>The Pi\u2011Hole Operator is still evolving. Expect frequent breaking changes and incomplete documentation.   If you encounter problems or have ideas, please open an issue or pull request on GitHub.</p>"},{"location":"#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>What We\u2019re Building</li> <li>Key Features</li> <li>Quick Start</li> <li>Architecture Overview</li> <li>Getting Started \u2013 Deploy a Cluster</li> <li>Contributing</li> <li>Documentation Links</li> </ol>"},{"location":"#what-were-building","title":"\ud83d\ude80 What We\u2019re Building","text":"<p>The Pi\u2011Hole Operator brings Kubernetes\u2011native management to a self\u2011hosted ad\u2011blocking DNS solution:</p> Target Why it matters Declarative Management One YAML file defines the entire Pi\u2011Hole cluster; the operator provisions, upgrades, and backs up automatically. Scalable DNS Run Pi\u2011Hole as a replicated deployment or StatefulSet, automatically load\u2011balancing queries. Automated Configuration Keep whitelist/blacklist, upstream servers, and custom settings in sync across all replicas. Health &amp; Observability Prometheus metrics, readiness/liveness probes, and integration with Kubernetes monitoring tools. Rolling Updates &amp; Rollbacks Zero\u2011downtime upgrades backed by a robust restore strategy."},{"location":"#key-features","title":"\u2728 Key Features","text":"<ul> <li>CRD (<code>PiHoleCluster</code>) \u2013 Exposes all Pi\u2011Hole configuration options as declarative fields.  </li> <li>StatefulSet Deployment \u2013 Persistent storage for logs, hosts files, and configuration.  </li> <li>Dynamic Upstream Management \u2013 Auto\u2011updates upstream DNS servers based on cluster topology or external secrets.  </li> <li>Metrics &amp; Alerts \u2013 Prometheus exporter for query counts, blocked domains, and latency; alerts for high failure rates.  </li> <li>Ingress &amp; LoadBalancer Support \u2013 Optional Ingress with cert\u2011manager TLS or public IP via <code>LoadBalancer</code>.  </li> <li>Helm\u2011OCI Chart \u2013 Easy installation from <code>ghcr.io/supporterino/pi-hole-operator/helm/pi-hole-operator</code>.  </li> </ul>"},{"location":"#quick-start","title":"\u26a1 Quick Start","text":"<pre><code># Install the OCI Helm chart (requires Helm 3.10+)\nhelm install pi-hole-operator \\\n  --namespace pi-hole-operator-system \\\n  --create-namespace \\\n  ghcr.io/supporterino/pi-hole-operator/helm/pi-hole-operator:latest\n</code></pre> <p>After the chart is deployed, create a <code>PiHoleCluster</code>:</p> <pre><code>apiVersion: v1alpha1.example.com/v1\nkind: PiHoleCluster\nmetadata:\n  name: demo\nspec:\n  replicas: 3          # read\u2011only replicas\n  ingress:\n    enabled: true\n    domain: \"pi.example.com\"\n  service:\n    type: LoadBalancer   # optional \u2013 expose via public IP\n</code></pre> <pre><code>kubectl apply -f demo.yaml\n</code></pre> <p>The operator will provision the deployment, service, ingress, and metrics automatically.</p>"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<pre><code>+-----------------+          +---------------------+\n| PiHoleCluster  | CRD      | Operator (manager) |\n+-----------------+ &lt;------&gt; +---------------------+\n          ^                     |\n          |                     v\n   +-----------+        +---------------+\n   | Deployment|        | Service/Ingress|\n   +-----------+        +---------------+\n          |\n          v\n     Pi\u2011Hole Pods (Read\u2011write + Replicas)\n</code></pre> <ul> <li>Controller watches <code>PiHoleCluster</code> resources and reconciles the desired state.</li> <li>Deployment hosts one read\u2011write pod + N replicas (configurable).</li> <li>Service exposes the cluster internally; <code>LoadBalancer</code> or Ingress can be used for external access.</li> <li>Metrics are exposed on <code>/metrics</code> and can be scraped by Prometheus.</li> </ul>"},{"location":"#contributing","title":"\ud83d\udc69\u200d\ud83d\udcbb Contributing","text":"<ol> <li>Fork the repo and create a feature branch (<code>git checkout -b feat/your-feature</code>).</li> <li>Run tests before committing:    <pre><code>make test          # unit tests\nmake test-e2e      # e2E tests (requires kind/minikube)\n</code></pre></li> <li>Follow the Go style (<code>go fmt</code>), keep changes focused, and add tests for new logic.</li> <li>Open a PR \u2013 we\u2019ll review and merge if it meets the guidelines.</li> </ol>"},{"location":"#documentation-links","title":"\ud83d\udcd6 Documentation Links","text":"Topic Link Installation &amp; Upgrade https://supporterino.de/pi-hole-operator/docs/installation Usage &amp; CRD Reference https://supporterino.de/pi-hole-operator/docs/usage Architecture &amp; Design https://supporterino.de/pi-hole-operator/docs/architecture Troubleshooting https://supporterino.de/pi-hole-operator/docs/troubleshooting FAQ https://supporterino.de/pi-hole-operator/docs/faq <p>Note: The documentation site is hosted at https://supporterino.de/pi-hole-operator/.  Browse the sections above for detailed guidance.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>The Pi\u2011Hole Operator follows the classic Kubernetes operator pattern. Below is a high\u2011level diagram followed by a component\u2011by\u2011component walk\u2011through.</p> <pre><code>+-----------------+          +---------------------+\n| PiHoleCluster  | CRD      | Operator (manager) |\n+-----------------+ &lt;------&gt; +---------------------+\n          ^                            |\n          |                            v\n   +-----------+                +---------------+\n   | Deployment|  (read\u2011write + replicas) |\n   +-----------+                +---------------+\n          |                            |\n          v                            v\n     Pi\u2011Hole Pods (dnsmasq)      Service / Ingress\n          |                            |\n          +-----------+    +------------+\n                      |    |  Metrics   |\n                      +----&gt;+ (Prometheus)|\n                           +------------+\n</code></pre>"},{"location":"architecture/#components","title":"Components","text":"Component Responsibility CRD (<code>PiHoleCluster</code>) Declarative description of the desired Pi\u2011Hole cluster (replicas, ingress, config). Controller Manager Watches <code>PiHoleCluster</code> resources and reconciles the Deployment, Service, Ingress, ConfigMap, Secrets. Deployment Runs one read\u2011write Pi\u2011Hole pod and N read\u2011only replicas. Uses a shared PVC for persistence (optional). Service Exposes the Pi\u2011Hole DNS port (<code>53/udp</code>) internally. Can be a <code>LoadBalancer</code> if required. Ingress Optional HTTPS ingress that terminates TLS via cert\u2011manager and forwards to the service. Metrics Exporter container (sidecar or embedded) exposing <code>/metrics</code> for Prometheus. Webhook Mutating/Validating admission webhook that ensures CR validity and injects default values. TLS is provided by cert\u2011manager."},{"location":"architecture/#data-flow","title":"Data Flow","text":"<ol> <li>User creates a <code>PiHoleCluster</code> CR.</li> <li>The operator receives the event, validates it via the webhook, and starts reconciliation.</li> <li>It creates/updates the Deployment (read\u2011write + replicas) and a Service.</li> <li>If <code>ingress.enabled</code>, the operator creates an Ingress and requests a TLS cert.</li> <li>The operator watches the Pi\u2011Hole pods\u2019 API, syncing configuration and ad\u2011lists from the specified sources.</li> <li>Metrics are exposed on <code>/metrics</code> and can be scraped by Prometheus.</li> </ol>"},{"location":"architecture/#persistence","title":"Persistence","text":"<p>The operator uses a <code>PersistentVolumeClaim</code> for the Pi\u2011Hole data directory (<code>/etc/pihole</code>). You can customize storage size via <code>spec.persistence.size</code> in the CR.</p> <p>Next</p> <ul> <li>Usage \u2013 How to create a <code>PiHoleCluster</code>.</li> <li>Troubleshooting \u2013 Common problems and fixes.</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":"Question Answer Can I expose Pi\u2011Hole via a LoadBalancer? Yes. Set <code>spec.service.type: LoadBalancer</code> in the Helm values or the CR. The operator will create a Service of that type and expose port\u202f53/UDP. How do I upgrade the operator? Use Helm: <code>helm repo update</code> then <code>helm upgrade pi-hole-operator oci://ghcr.io/supporterino/pi-hole-operator/helm/pi-hole-operator --namespace pi-hole-operator-system</code>. Where are the Pi\u2011Hole logs stored? They\u2019re in the pod logs. Use <code>kubectl logs deployment/&lt;pihole-cluster&gt; -n pi-hole-operator-system</code>. For persistent storage, mount a PVC to <code>/etc/pihole</code> in the Deployment. Can I use custom ad\u2011lists? Yes. Add URLs under <code>spec.config.adLists</code> in the <code>PiHoleCluster</code> CR. The operator will fetch and sync them every 5\u202fminutes (configurable). Is cert\u2011manager required for TLS? No. Ingress TLS is optional; if you set <code>ingress.enabled=true</code> and have cert\u2011manager installed, the operator will request a certificate automatically. Without cert\u2011manager you can still use Ingress but must provide your own TLS secret. Does the operator support StatefulSets? Currently it uses a Deployment with read\u2011only replicas. If you need stateful behavior, mount the same PVC to all pods; the operator already supports a shared PVC via <code>spec.persistence</code>. How can I contribute? Fork the repo, create a feature branch, run <code>make test</code> and open a PR. See our Contribution Guide."},{"location":"installation/","title":"Installation","text":"<p>The Pi\u2011Hole Operator is distributed as an OCI Helm chart. Below are the steps for a fresh install, plus optional values you can tweak.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"Component Minimum version Helm 3.10+ (OCI support) Kubernetes 1.28+ cert\u2011manager (optional) \u2265\u202f1.12 <p>If you plan to use the operator\u2019s Ingress or LoadBalancer features, make sure your cluster supports those resources (e.g., GKE/EKS).</p>"},{"location":"installation/#1-add-the-oci-registry","title":"1\ufe0f\u20e3 Add the OCI registry","text":"<pre><code># Log in to GitHub Container Registry (once per shell session)\nhelm registry login ghcr.io\n\n# Optional: add a Helm repo for convenience\nhelm repo add pi-hole-operator https://ghcr.io/supporterino/pi-hole-operator/helm/pi-hole-operator\n</code></pre> <p>The chart is available under the OCI path <code>ghcr.io/supporterino/pi-hole-operator/helm/pi-hole-operator</code>.</p>"},{"location":"installation/#2-install-the-chart","title":"2\ufe0f\u20e3 Install the chart","text":"<pre><code># Pull the latest image (optional, useful for offline installs)\nhelm pull oci://ghcr.io/supporterino/pi-hole-operator/helm/pi-hole-operator --version latest\n\n# Install the chart directly from OCI\nhelm install pi-hole-operator \\\n  oci://ghcr.io/supporterino/pi-hole-operator/helm/pi-hole-operator \\\n  --namespace pi-hole-operator-system \\\n  --create-namespace\n</code></pre> <p>The chart installs the CRDs, RBAC, controller manager and all optional components.</p>"},{"location":"installation/#3-optional-values","title":"3\ufe0f\u20e3 Optional values","text":"<p>You can override any value by passing a custom <code>values.yaml</code> or using the <code>--set</code> flag.</p> Value Description Default <code>metrics.enabled</code> Enable Prometheus metrics exporter <code>true</code> <code>ingress.enabled</code> Create an Ingress for the Pi\u2011Hole service <code>false</code> <code>service.type</code> Service type (<code>ClusterIP</code>, <code>LoadBalancer</code>) <code>ClusterIP</code> <code>certmanager.enable</code> Enable cert\u2011manager webhook TLS <code>true</code> <p>Fetching the default values The project ships a helper called <code>mcp</code>.  Run:</p> <pre><code>mcp get-values pi-hole-operator\n</code></pre> <p>to print the chart\u2019s default <code>values.yaml</code> on your terminal.</p>"},{"location":"installation/#4-verify","title":"4\ufe0f\u20e3 Verify","text":"<pre><code>kubectl get pods -n pi-hole-operator-system\nkubectl describe deployment pi-hole-operator-controller-manager -n pi-hole-operator-system\n</code></pre> <p>If the operator pod is running and <code>READY</code> shows <code>1/1</code>, you\u2019re good to go!</p> <p>Next steps</p> <ul> <li>Usage \u2013 Create your first <code>PiHoleCluster</code>.</li> <li>Architecture \u2013 Understand how the operator works.</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Below are the most common issues you might encounter, along with quick diagnostics and solutions.</p>"},{"location":"troubleshooting/#1-operator-pod-stuck-in-crashloopbackoff","title":"1\ufe0f\u20e3 Operator pod stuck in <code>CrashLoopBackOff</code>","text":"Symptom Likely cause Fix <code>CrashLoopBackOff</code> in <code>pi-hole-operator-controller-manager</code> Missing or invalid cert\u2011manager webhook configuration Ensure <code>certmanager.enable=true</code> in Helm values and that cert\u2011manager is running. Crash after startup Missing environment variables or secrets Verify <code>apiPassword</code> secret exists and is referenced correctly. Crash due to image pull error Wrong image tag or registry auth Use <code>helm upgrade</code> with the correct OCI image reference. <p>Command</p> <pre><code>kubectl logs deployment/pi-hole-operator-controller-manager -n pi-hole-operator-system\n</code></pre>"},{"location":"troubleshooting/#2-pihole-pods-not-starting","title":"2\ufe0f\u20e3 Pi\u2011Hole pods not starting","text":"Symptom Likely cause Fix Pods in <code>ImagePullBackOff</code> Registry credentials missing Add Docker config to the service account or use image pull secrets. Pods crash with <code>exit status 1</code> Invalid config (e.g., missing TZ) Check the ConfigMap or env vars; update the CR. Pods stuck in <code>Pending</code> Insufficient resources / PVC not bound Verify node capacity and that the PVC is correctly defined. <p>Command</p> <pre><code>kubectl describe pod &lt;pihole-pod&gt; -n pi-hole-operator-system\n</code></pre>"},{"location":"troubleshooting/#3-ingress-not-reachable","title":"3\ufe0f\u20e3 Ingress not reachable","text":"Symptom Likely cause Fix Ingress shows <code>ADDRESS</code> but DNS not resolving DNS record missing or incorrect Add a CNAME/ALIAS pointing to the Ingress controller\u2019s IP. TLS handshake fails cert\u2011manager not issuing cert Check <code>cert-manager.io/cluster-issuer</code> annotation and cert\u2011manager logs. HTTP 404 on <code>/metrics</code> Service selector mismatch Verify the service selector matches the Pi\u2011Hole pods. <p>Command</p> <pre><code>kubectl describe ingress &lt;ingress-name&gt; -n pi-hole-operator-system\n</code></pre>"},{"location":"troubleshooting/#4-metrics-not-exposed","title":"4\ufe0f\u20e3 Metrics not exposed","text":"Symptom Likely cause Fix <code>/metrics</code> returns 404 Metrics sidecar not deployed or wrong port Ensure <code>metrics.enabled=true</code> in Helm values. Prometheus scrape fails ServiceMonitor not created Verify <code>metrics.serviceMonitor.enabled=true</code> and that the Prometheus instance is configured to scrape it. <p>Command</p> <pre><code>kubectl port-forward svc/pi-hole-metrics 9100 -n pi-hole-operator-system\ncurl http://localhost:9100/metrics\n</code></pre>"},{"location":"troubleshooting/#5-adlists-not-syncing","title":"5\ufe0f\u20e3 Ad\u2011lists not syncing","text":"Symptom Likely cause Fix No new entries in Pi\u2011Hole UI <code>spec.sync.adLists=false</code> or URL unreachable Set <code>sync.adLists=true</code> and ensure URLs are reachable from the operator pod. Sync errors in logs Authentication or network issue Check logs: <code>kubectl logs deployment/pi-hole-operator-controller-manager</code>. <p>General debugging</p> <pre><code># Operator logs\nkubectl logs deployment/pi-hole-operator-controller-manager -n pi-hole-operator-system\n\n# Pi\u2011Hole pod logs\nkubectl logs deployment/&lt;pihole-cluster&gt; -n pi-hole-operator-system\n\n# Inspect CR status\nkubectl get piholecluster &lt;name&gt; -o yaml | grep -A5 status\n</code></pre> <p>If you can\u2019t resolve the issue, feel free to open an issue on GitHub with the relevant logs and a description of what you\u2019ve tried.</p>"},{"location":"usage/","title":"Usage","text":"<p>Once the operator is running, you create a PiHoleCluster custom resource that describes your desired Pi\u2011Hole deployment.</p>"},{"location":"usage/#1-create-a-secret-for-the-api-password","title":"1\ufe0f\u20e3 Create a secret for the API password","text":"<pre><code>kubectl create secret generic pihole-secret \\\n  --namespace pi-hole-operator-system \\\n  --from-literal=password='YOUR_PIHOLE_PASSWORD'\n</code></pre> <p>The password is used by the operator to authenticate against the Pi\u2011Hole API.</p>"},{"location":"usage/#2-define-a-piholecluster","title":"2\ufe0f\u20e3 Define a <code>PiHoleCluster</code>","text":"<pre><code>apiVersion: v1alpha1.example.com/v1\nkind: PiHoleCluster\nmetadata:\n  name: demo-cluster\nspec:\n  replicas: 3                # number of read\u2011only replicas\n  ingress:\n    enabled: true\n    domain: \"pi.example.com\"\n  service:\n    type: LoadBalancer        # optional \u2013 expose via public IP\n  config:\n    apiPassword:\n      secretRef:\n        name: pihole-secret\n        key: password\n    env:\n      TZ: \"Europe/Berlin\"\n  sync:\n    config: true\n    adLists: true\n</code></pre> <p>Replace <code>pi.example.com</code> with your real domain and adjust the environment variables as needed.</p>"},{"location":"usage/#3-apply-the-cr","title":"3\ufe0f\u20e3 Apply the CR","text":"<pre><code>kubectl apply -f demo-cluster.yaml\n</code></pre> <p>The operator will:</p> <ol> <li>Create a Deployment with one read\u2011write pod + 3 replicas.</li> <li>Expose the service (<code>ClusterIP</code> by default, <code>LoadBalancer</code> if set).</li> <li>Create an Ingress (if enabled) and request a TLS cert via cert\u2011manager.</li> <li>Sync Pi\u2011Hole configuration and ad\u2011lists.</li> </ol>"},{"location":"usage/#4-verify-the-deployment","title":"4\ufe0f\u20e3 Verify the deployment","text":"<pre><code># List pods\nkubectl get pods -n pi-hole-operator-system\n\n# View operator logs (for troubleshooting)\nkubectl logs deployment/pi-hole-operator-controller-manager -n pi-hole-operator-system\n\n# Check Pi\u2011Hole pod logs\nkubectl logs deployment/demo-cluster -n pi-hole-operator-system\n\n# Test DNS resolution (replace &lt;service-ip&gt; with the actual IP)\ndig @&lt;service-ip&gt; example.com\n\n# View metrics (port\u2011forward if needed)\nkubectl port-forward svc/demo-cluster-metrics 9100 -n pi-hole-operator-system\ncurl http://localhost:9100/metrics\n</code></pre>"},{"location":"usage/#5-common-operations","title":"5\ufe0f\u20e3 Common operations","text":"Operation Command Scale replicas <code>kubectl patch piholecluster/demo-cluster -p '{\"spec\":{\"replicas\":5}}'</code> Update ad\u2011lists Edit <code>spec.config.adLists</code> in the CR and reapply Rolling upgrade of Pi\u2011Hole image Update the <code>image</code> field in the Deployment or use a Helm upgrade with new chart version <p>Next</p> <ul> <li>Architecture \u2013 Dive into how the operator reconciles resources.</li> <li>Troubleshooting \u2013 Fix common issues you might encounter.</li> </ul>"}]}